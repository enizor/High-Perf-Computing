%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Programming/Coding Assignment
% LaTeX Template
%
% This template has been downloaded from:
% http://www.latextemplates.com
%
% Original author:
% Ted Pavlic (http://www.tedpavlic.com)
%
% Note:
% The \lipsum[#] commands throughout this template generate dummy text
% to fill the template out. These commands should all be removed when
% writing assignment content.
%
% This template uses a Perl script as an example snippet of code, most other
% languages are also usable. Configure them in the "CODE INCLUSION
% CONFIGURATION" section.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[11pt, a4paper]{article}

\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage[usenames,dvipsnames]{color} % Required for custom colors
\usepackage{graphicx} % Required to insert images
\usepackage{listings} % Required for insertion of code
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{stmaryrd}
\usepackage{algpseudocode}
\usepackage[frenchb]{babel}
\usepackage{dsfont}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{textcomp}
% \usepackage{times}
% Margins
% \topmargin=-0.45in
\evensidemargin=0.25in
\oddsidemargin=0.25in
% \marginparwidth=2cm
\textwidth=6in
% \textheight=9.0in
% \headsep=0.25in

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{} % Top left header
\chead{\hmwkTitle} % Top center head
\rhead{} % Top right header
\lfoot{\hmwkAuthorName} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Page\ \thepage\ sur\ \protect\pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs

%----------------------------------------------------------------------------------------
%	CODE INCLUSION CONFIGURATION
%----------------------------------------------------------------------------------------

\lstloadlanguages{C} % Load Perl syntax for listings, for a list of other languages supported see: ftp://ftp.tex.ac.uk/tex-archive/macros/latex/contrib/listings/listings.pdf
\lstset{texcl=true, columns=flexible,basicstyle=\ttfamily}

\lstdefinestyle{ccode}{language=C, % Use Perl in this example
        frame=single, % Single frame around code
        basicstyle=\ttfamily, % Use true type font
        keywordstyle=[1]\color{Blue}, % Perl functions bold and blue
        keywordstyle=[2]\color{Green}, % Perl function arguments purple
        keywordstyle=[3]\color{Blue}, % Custom functions underlined and blue
        identifierstyle=, % Nothing special about identifiers
        commentstyle=\small\color{Brown}, % Comments small dark green courier font
        stringstyle=\color{OliveGreen}, % Strings are purple
        showstringspaces=false, % Don't put marks in string spaces
        tabsize=5, % 2 spaces per tab
        %
        % Put standard Perl functions not included in the default language here
        morekeywords={f, sequantial_computation, parallel_computation, printf},
        morecomment=[l][\color{Blue}]{...}, % Line continuation (...) like blue comment
        numbers=left, % Line numbers on left
        firstnumber=1, % Line numbers start with line 1
        numberstyle=\tiny\color{Blue}, % Line numbers are blue and small
        stepnumber=5, % Line numbers go in steps of 5
        texcl=true,
        columns=flexible
}

% Creates a new command to include a perl script, the first parameter is the filename of the script (without .pl), the second parameter is the caption
\newcommand{\cscript}[2]{
\begin{itemize}
\item[]\lstinputlisting[caption=#2,label=#1]{#1.pl}
\end{itemize}
}


\newcommand{\problemAnswer}[1]{ % Defines the problem answer command with the content as the only argument
\noindent\framebox[\columnwidth][c]{\begin{minipage}{0.98\columnwidth}#1\end{minipage}} % Makes the box around the problem answer and puts the content inside
}

%----------------------------------------------------------------------------------------
%	NAME AND CLASS SECTION
%----------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Projet final : Parallélisation de l'algorithme de Jacobi} % Assignment title
\newcommand{\hmwkClass}{High Performance Computing} % Course/class
\newcommand{\hmwkAuthorName}{Rémi Garde} % Your name

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title{
\LARGE{\textbf{\hmwkClass}}\\
\vspace{0.5in}
\large{\textbf{\hmwkTitle}}
\vspace{3in}
}

\author{\textbf{\hmwkAuthorName}}
\date{Mars 2018} % Insert date here if you want it to appear below your name

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS
%----------------------------------------------------------------------------------------

%\setcounter{tocdepth}{1} % Uncomment this line if you don't want subsections listed in the ToC

\newpage
\tableofcontents
\newpage

%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------

% To have just one problem per page, simply put a \clearpage after each problem

\section{Méthode de Jacobi}

\subsection{Définition du problème}

Soit $n \in \mathds{N}$, $A = (a_{ij})_{(i,j)\in \llbracket 1,n \rrbracket^2}$ une matrice carrée de taille $n$, $B = (b_{i})_{i\in \llbracket 1,n \rrbracket}$ un vecteur de taille $n$.
Nous cherchons à résoudre le système d'équations linéaires
\begin{equation} \label{eq:problem}
    AX=B
\end{equation}
pour $X = (x_{i})_{i\in \llbracket 1,n \rrbracket}$ vecteur de taille $n$.

\subsection{Résolution}

Pour résoudre ce problème, $A$ est séparée en 2 matrices $D$ et $R$, avec $D$ matrice de la diagonale de $A$ et $R$ les éléments non diagonaux de $A$ :
\[
A =
 \begin{pmatrix}
  a_{1,1} & a_{1,2} & \cdots & a_{1,n} \\
  a_{2,1} & a_{2,2} & \cdots & a_{2,n} \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  a_{n,1} & a_{n,2} & \cdots & a_{n,n}
 \end{pmatrix}
 =
  \begin{pmatrix}
  a_{1,1} & 0 & \cdots & 0 \\
  0 & a_{2,2} & \cdots & 0 \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  0 & 0 & \cdots & a_{n,n}
 \end{pmatrix}
 +
  \begin{pmatrix}
  0 & a_{1,2} & \cdots & a_{1,n} \\
  a_{2,1} & 0 & \cdots & a_{2,n} \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  a_{n,1} & a_{n,2} & \cdots & 0
 \end{pmatrix}
\]
Ceci est intéressant car le calcul de $D^{-1}$ est trivial :
\[
D^{-1} =
  \begin{pmatrix}
  \frac{1}{a_{1,1}} & 0 & \cdots & 0 \\
  0 & \frac{1}{a_{2,2}} & \cdots & 0 \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  0 & 0 & \cdots & \frac{1}{a_{n,n}}
 \end{pmatrix}
\]
La formulation \eqref{eq:problem} devient donc équivalente à \((D+R)X=B\)
ce qui donne:
\begin{equation} \label{eq:reeq}
    X = D^{-1} (B-RX)
\end{equation}

Nous pouvons ensuite poser la suite $X^{(k)}, n \in \mathds{N}$ définie comme suit:

\[
\left\{
    \begin{array}{lr}
        X^{(0)} = 0 \\
        X^{(k+1)} = D^{-1} (B-RX^{(k)}),& k \in \mathds{N}^*
    \end{array}
\right.
\]

La formule de récurrence s'écrit pour chacun des éléments de X :

\begin{equation} \label{eq:rec}
    \forall k \in \mathds{N}^*, \forall i \in \llbracket 1,n \rrbracket,
    x^{(k+1)}_i = \frac{1}{a_{ii}} (b_i - \sum_{i \neq j} a_{ij}x^{(k)}_j)
\end{equation}

\newpage
\subsection{Convergence}

Déterminons une condition telle que \(\lim_{k \to \infty} X^{(k)} = X\)).
En posant \( A^\prime = -D^{-1}R\) et

\( B^\prime = D^{-1}B \),
\eqref{eq:reeq} devient alors :

\[
    X = A^\prime X + B^\prime
\]
et ainsi

\[
    X^{(k+1)} - X = A^\prime X^{(k)} + B^\prime - (A^\prime X + B^\prime)
    =  A^\prime (X^{(k)} - X)
\]
ce qui indique
\[
    \lim_{k \to \infty} \| X^{(k+1)} - X \| = 0 \Leftrightarrow \rho(A^\prime) < 1
\]

On remarque que les coefficients de \( A^\prime \) s'écrivent:
\[
    a^\prime_{i,j} = \left\{
        \begin{array}{lr}
            0 & \text{si } i = j \\
            \frac{-a_{ij}}{a_{ii}} & \text{si } i \neq j
        \end{array}
    \right.
\]

Soit \( \lambda \) une valeur propre de \( A^\prime \) et \( Y = (y_i) \)
un vecteur propre associé.
\( A^\prime Y = \lambda Y \) donne donc pour tout \(i\) :
\begin{align*}
    \|\lambda Y\|_\infty &= | \sum_j a^\prime_{ij} y_j | \\
    |\lambda| \cdot\| Y\|_\infty &= | \sum_{j \neq i} \frac{-a_{ij}}{a_{ii}} y_j | \\
    |\lambda| \cdot\| Y\|_\infty &= |\frac{1}{a_{ii}}| \cdot | \sum_{j \neq i} -a_{ij} y_j| \\
    |\lambda| \cdot\| Y\|_\infty &\leq |\frac{1}{a_{ii}}| \sum_{j \neq i} |a_{ij} y_j|\\
    |\lambda| \cdot\| Y\|_\infty &\leq |\frac{1}{a_{ii}}| \sum_{j \neq i} |a_{ij}| \cdot\| Y\|_\infty
\end{align*}

Or, pour toute matrice \( M = (m_{ij}) \) à diagonale strictement dominante :
\[
    \forall i, |m_{ii}| > \sum_{j \neq i} |m_{ij}|
\]

Ainsi, si \( A \) est diagonale strictement dominante, alors son rayon spectral est inférieur à 1, ce qui fait converger la méthode de Jacobi.

\newpage
\section{Implémentation}
\subsection{Structures de données}
J'ai choisi de représenter mes matrices et vecteurs de façon très simple :
des tableaux de \lstinline{double} et des entiers présentant les dimensions du tableau.
Les deux fichiers les implémentant, \texttt{matrix.c} et \texttt{vector.c} sont donc très similaires.
Ils contiennent des fonctions très simples pour la création, destruction et l'affichage de leur données, ainsi qu'une fonction leur permettant la création depuis un fichier. Cette dernière ne va charger qu'une partie de la matrice ou du vecteur pour limiter l'utilisation de mémoire.

\bigskip
Cette structure de données n'est pas idéale pour les matrices, car dans les cas réels elles seront creuses, diminuant de beaucoup l'efficacité mémoire.
Une amélioration possible serait de réécrire \texttt{matrix.c} en l'implémentant sous la forme de tableaux représentant les coordonnées des valeurs.
On gagnera ainsi en taille mémoire, et l'on perdra en temps d'accès aux valeurs.

\subsection{Parallélisation}

On cherche donc à paralléliser \eqref{eq:rec}.
Pour cela, on va partager les \(n\) lignes entre les \(q\) processus.
Cela donne les relations suivantes pour un processus n\textdegree\(p\), en notant \(d = \lfloor \frac{n}{p} \rfloor\) et \(r = \text{mod}(n,p)\) :
    % num_rows = dim_row / mpi_size;
    % first_row = rank * (dim_row / mpi_size);
\begin{itemize}
    \item Nombre de lignes:  \(d\) si \(p<r\), \(d+1\) sinon;
    \item Sa première ligne est \(dp+\text{min}(r,p)\)
    \item le processus contenant la ligne \(i\) est le n\textdegree\(\lfloor \frac{iq}{n} \rfloor\)
\end{itemize}
Ces relations sont valables pour une numérotation des lignes et des processus commençant tous deux à 0.
Cela correspond aux variables \lstinline{num_rows} et
\lstinline{first_row} dans le code.

\bigskip

Bien sûr, une telle séparation n'est a priori pas réalisable, le calcul de \(x_i\) dépendant des \(x_j, j \neq i\).
Pour y remédier, chaque processus va contenir deux vecteurs : \lstinline{x_local} et \lstinline{x_global}.
Le premier correspond aux lignes spécifiques aux processus, le deuxième à la totalité du vecteur \(X^{(k)}\).
Lors de chaque itérations, les processus commencent par envoyer à chacun leurs valeurs dans leur \lstinline{x_local}.
Tous les processus remplissent alors \lstinline{x_global}, ce qui leur permet de calculer la nouvelle itération de \lstinline{x_local}.
Il ne reste plus qu'à répéter cette opération jusqu'à ce qu'on soit satisfait de l'approximation de \(X\) obtenue.

\newpage
\subsection{Arrêt}

Afin de déterminer l'erreur commise \(\epsilon_k = \|X^{(k)} - X \|_\infty\), la première réaction est de calculer \(AX^{k}-b = A(X^{k}-X)\).
Cependant c'est là un nouveau calcul de produit matrice-vecteurs, que l'on cherche justement à accélérer.

En remarquant qu'en fin d'itération, \lstinline{x_local} correspond à \(X^{(k+1)}\) et \lstinline{x_global} à \(X^{(k)}\), on va plutôt calculer :
\(    \mu_k = \| X^{(k+1)} - X^{(k)} \|_\infty \).
En effet :
\begin{align*}
    \mu_k &= \| A^\prime X^{(k)} + B^\prime - X^{(k)} \|_\infty \\
    &= \| A^\prime X^{(k)} + X - A^\prime X- X^{(k)} \|_\infty \\
    &= \| A^\prime (X^{(k)} - X) - ( X^{(k)} - X ) \|_\infty \\
    \mu_k &\geq \left| \| A^\prime (X^{(k)} - X) \|_\infty - \epsilon_k \right|
\end{align*}

Or, nous avions vu que pour la convergence, le rayon spectral de \(A^\prime\) est nécessairement strictement inférieur à 1.
Donc \(\| A^\prime (X^{(k)} - X) \|_\infty \leq \epsilon_k \) et enfin
\(\mu_k \geq \epsilon_k\).

Ainsi, pour obtenir une valeur approchée de \(X\) à \(10^{-6}\) près,
il suffira d'itérer jusqu'à obtenir une différence entre \lstinline{x_local}
et \lstinline{x_global} de moins de \(10^{-6}\).

\bigskip

En pratique, pour limiter le nombre de calculs, à chaque coefficient
\lstinline{x_local[i]} on associe un booléen \lstinline{residues[i]}
qui indique si \(x^{(k)}_i\) doit encore itérer.
Si ce n'est pas le cas, on ne fais plus le calcul associé : \(x^{(k+1)}_i = x^{(k)}_i\).
Pour tester la fin du programme dans sa totalité, chaque processus va vérifier
si au moins une valeur de \lstinline{residues} est à \lstinline{true}.
Ensuite chaque processus va envoyer ce résultat \lstinline{local_continue} au premier processus, qui va pouvoir déterminer si le la solution est suffisamment bien approchée dans sa globalité.
Il répondra donc à tous les processus un ordre de continuer ou de s'arrêter suivant le cas, gérée par la variable \lstinline{run}.

\newpage
\subsection{Communication entre les processus}

Avec ce qui a été dit précédemment, nous avons 2 communications à faire :
la première le partage de \lstinline{x_local} avec tous les autres processus,
la deuxième la mise en commun des \lstinline{local_continue}.

\bigskip

Pour partager le vecteur \lstinline{x_local}, chaque processus va itérer sur la ligne \(i\).
On détermine d'abord quel processus continent le coefficient \(x_i\),
et ce processus va envoyer cette valeur à tous les autres, dans l'ordre,
soit \((q-1)\) \lstinline{MPI_Send} avec q nombre de processus.
Les autres processus ont juste à faire un \lstinline{MPI_Recv}.

Quant au partage de \lstinline{local_continue},
il suffit à chaque processus autre que 0 un \lstinline{MPI_Send}, et
\((q-1)\) \lstinline{MPI_Recv} pour le processus 0, et les opérations inverses
pour le partage du \lstinline{global_continue}

\bigskip

Deux modèles de communications sont possibles : un format synchrone,
où chaque opération est bloquante, et un format asynchrone, où les opérations
de communications ne sont pas bloquantes, et l'on doit utiliser d'autres fonctions
pour savoir lorsqu'elles ont eu lieu.
On peut gagner beaucoup de temps grâce à l'asynchrone ici :
chaque coefficient peut être récupéré indépendamment, et il suffit se savoir
quand tous ces coefficients ont été transmis.
Pour cela, on change les \lstinline{MPI_Send} en \lstinline{MPI_Isend},
les \lstinline{MPI_Recv} en \lstinline{MPI_Irecv}, en rajoutant en argument
une \lstinline{MPI_Request} qui permettra ensuite de tester sa complétion.
Cependant il est ici inutile de tester directement la complétion d'une requête particulière,
il suffit de rajouter un \lstinline{MPI_Barrier} après le bloc d'envoi et de réception.
Chaque processus va alors créer ses requêtes, chacun à sa vitesse, puis s'arrêter sur le \lstinline{MPI_Barrier} jusqu'à ce que tous les processus y soient.
Alors le process reprendra son cours.

Dans le code, le choix du mode de communication se fait en fonction du 5e argument \lstinline{argv[5]} : 0 pour synchrone, 1 pour asynchrone, 2 pour asynchrone et enlever les \lstinline{MPI_Barrier}.
Dans ce dernier cas, on va overrider les résidus : en effet si aucun des messages n'a été transmis, \(X^{(k+1)} = X^{(k)} \) et l'on arrêtera d'itérer dessus.
Le programme stoppera quand il atteindra la limite d'itérations, 5000.
Un \lstinline{MPI_Barrier} à ce moment récupèrera les requête perdues.
Attention cependant: le nombre total de requêtes vaut : \( 5000nq \), si les itérations sont finies avant que les réquêtes aient été reçues, cela fait une quantité de mémoire non négligeable.
\newpage

\section{Résultats}

Le code est compilé et lancé comme suit :
\begin{lstlisting}[language=bash, keywordstyle=\color{black}\bf]
$ mpicc code/*.c -o out
$ mpirun -n <number_of_processors> ./out \
    <matrix_size> <matrix_file_path> <vector_file_path> <sync_type>
$  mpirun -n 2 ./out 20 examples/mat20.txt examples/vec20.txt 0
\end{lstlisting}

avec \lstinline{<sync_type>} correspondant à 0 pour synchrone, 1 pour asynchrone,
et 2 pour asynchrone sans \lstinline{MPI_Barrier}

\bigskip

Dans le dossier \texttt{examples} je proposes quelques exemples de matrices à diagonale strictement dominante, de tailles respectives 4, 20, et 300.

Je ne remarque pas de différence en temps d'éxécutions entre le synchrone et l'asynchrone. Cependant mon choix d'arrêt au bout de 5000 itérations rend dans tous les cas l'asynchrone sans \lstinline{MPI_Barrier} plus lent.
De même, la différence est minime lorsque je change la taille de la matrice en restant raisonnable (\(n \leq 300\)).
Les 3 exemples de tailles 4, 20 et 300 sont des matrices denses.

Le programme n'est plus instantané pour mon exemple de taille 5000.
Cet exemple est contenu dans un fichier zip supplémentaire pour vous laisser le choix de son utilisation, car décompréssée la matrice fait 50Mo.
Il s'agit d'une matrice creuse, où seules les 5 diagonales les plus proches du
centre sont remplies. Le programme finit en quelques secondes toutefois, au bout de 24 itérations.
L'impact mémoire, de quelques centaines de Mo, est pour la première fois sensible.

\bigskip

Utiliser l'asynchrone sans \lstinline{MPI_Barrier} ne marche pas très bien.
On s'aperçoit que quelques coefficients sont itérés, mais pas tous.
Je suppose que le programme itère plus vite que MPI parvient à faire les requêtes.
Je pense donc que même dans ce cas, l'algorithme converge au temps (beaucoup plus) long.
\end{document}
